{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "print(word2vec.FAST_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('../data/news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas teen tackled by cop at pool party files ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1483629018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Kerry In Leaked Audio Admits U.S. Allowed...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1483872751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017 American Liberty 225th Anniversary Gold C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1484327875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Repair broken glass with Sensible cost | Call ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1484798494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today is the last day to register for Obamacare</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1485872414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score  num_comments  \\\n",
       "0  Texas teen tackled by cop at pool party files ...      0             0   \n",
       "1  John Kerry In Leaked Audio Admits U.S. Allowed...      0             0   \n",
       "2  2017 American Liberty 225th Anniversary Gold C...      0             0   \n",
       "3  Repair broken glass with Sensible cost | Call ...      0             0   \n",
       "4    Today is the last day to register for Obamacare      0             0   \n",
       "\n",
       "   created_utc  \n",
       "0   1483629018  \n",
       "1   1483872751  \n",
       "2   1484327875  \n",
       "3   1484798494  \n",
       "4   1485872414  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "pattern = r'[\\d.,]+|[A-Z][.A-Z]+\\b\\.*|\\w+|\\S'\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "\n",
    "def prepare_corpus(sentences, tok):\n",
    "    tok_sentences = [tok.tokenize(x) for x in sentences]\n",
    "    return [[x.lower() for x in y if x not in string.punctuation] for y in tok_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_corpus = prepare_corpus(news['title'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['texas',\n",
       " 'teen',\n",
       " 'tackled',\n",
       " 'by',\n",
       " 'cop',\n",
       " 'at',\n",
       " 'pool',\n",
       " 'party',\n",
       " 'files',\n",
       " 'lawsuit']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_model = gensim.models.Word2Vec(news_corpus,\n",
    "                                    sg=0, # CBOW vs. skip-gram\n",
    "                                    size=100, # feature vectors' length\n",
    "                                    window=5, # window size\n",
    "                                    min_count=1, # ignore all words with total frequency lower than this\n",
    "                                    negative=1, # if set to 0, no negative samping is used\n",
    "                                    seed=123\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.703736903364041"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_model.wv.similarity('poland', 'u.s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55689644623002"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_model.wv.similarity('poland', 'czech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22361810944524252"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_model.wv.similarity('poland', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actress', 0.8806039690971375),\n",
       " ('playboy', 0.8434235453605652),\n",
       " ('chris', 0.8396222591400146),\n",
       " ('mary', 0.8303409218788147),\n",
       " ('vinod', 0.8268942832946777),\n",
       " ('singer', 0.8241496682167053),\n",
       " ('kapoor', 0.8117820620536804),\n",
       " ('mlb', 0.8042533993721008),\n",
       " ('bruce', 0.803532600402832),\n",
       " ('bryan', 0.800155520439148)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_model.wv.most_similar(positive=['woman', 'actor'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9511879400496241"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_model.wv.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_csv('../data/gaming.csv')\n",
    "games_corpus = prepare_corpus(games['title'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_model = gensim.models.Word2Vec(games_corpus,\n",
    "                                     min_count=1,\n",
    "                                     seed=123\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse\n",
      "Games: keyboard, monitor, headphones, headset, laptop, usb, mechanical, calibrator, wireless, router\n",
      "News: color, perfume, glasses, lip, bifold, applique, herbalife, workout, hoodies, pawn\n",
      "\n",
      "bomb\n",
      "Games: grenade, dirty, headshot, collateral, camper, shotgun, plane, night., quad, rat\n",
      "News: deadly, attack, incident, syrian, terror, weapons, ship, terrorist, strikes, jewish\n",
      "\n",
      "blood\n",
      "Games: knights, chaos, quest, slayer, necromancer, knight, gatez, puscaria, lazarski, samurai\n",
      "News: cancer, patient, alcohol, dementia, disease, brain, organs, excessive, ptsd, epilepsy\n",
      "\n",
      "war\n",
      "Games: mordor, bloodsheddayz, snowzilla, wardayz, hanzozeib, morder, warcraft, annihilation, shortround, 402\n",
      "News: nuclear, syria, peace, threat, conflict, iran, catastrophe, missiles, moab, democracy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_most_similar(word, top_n=10):\n",
    "    games_set = games_model.wv.most_similar(word, topn=top_n)\n",
    "    news_set = news_model.wv.most_similar(word, topn=top_n)\n",
    "    games_set = [x[0] for x in games_set]\n",
    "    news_set = [x[0] for x in news_set]\n",
    "    print(word)\n",
    "    print('Games:', ', '.join(games_set))\n",
    "    print('News:', ', '.join(news_set))\n",
    "    print()\n",
    "\n",
    "    \n",
    "print_most_similar('mouse')\n",
    "print_most_similar('bomb')\n",
    "print_most_similar('blood')\n",
    "print_most_similar('war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-workshop",
   "language": "python",
   "name": "nlp-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
